# 基于Transformer的运动模糊图片修复模型

为了有效地修复运动模糊的图片，我们提出了一种融合卷积神经网络（CNN）和Transformer的新型深度学习模型。该模型利用CNN的局部特征提取能力和Transformer的全局建模能力，能够更好地捕捉图像中的细节和全局信息，从而提高去模糊的效果。

## 模型思路
1. 背景
传统的去模糊方法主要依赖于卷积神经网络。然而，CNN在捕捉长距离依赖和全局信息方面存在局限性。而Transformer模型在自然语言处理和计算机视觉中展现了强大的全局建模能力。

2. 模型结构
我们的模型主要包括以下几个部分：
特征提取模块：使用浅层卷积层提取图像的低级特征。
残差块（Residual Blocks）：多个残差块用于深化网络，增强特征表达能力。
自注意力模块（Self-Attention Module）：引入Transformer的自注意力机制，捕捉图像的全局依赖关系。
重建模块：将经过自注意力模块处理的特征进行重建，生成去模糊的图像。
残差连接（Skip Connection）：输入和输出之间的直连，帮助模型学习残差，提高训练效果。

3. 模型创新点
融合Transformer与CNN：首次将Transformer的自注意力机制与CNN相结合，用于运动模糊图片的修复。
自适应的自注意力机制：针对图像去模糊任务，设计了适合图像特征的自注意力模块。
高效的网络结构：在保证模型性能的前提下，优化了模型的参数量和计算量。

## 环境配置

你可以使用以下命令安装所需的Python库：

```bash
pip install -r requirements.txt
```

## 数据准备

在项目目录下创建数据文件夹，并准备训练和测试数据集：
- data/blur：存放训练用的模糊图像。
- data/sharp：存放训练用的清晰图像。
- data/blur_test：存放测试用的模糊图像。
- data/sharp_test：存放测试用的清晰图像。

要训练去运动模糊的模型，需要成对的模糊图像和对应的清晰图像。以下是获取这种数据的方法：

### 使用公开数据集

- GoPro Dataset：一个广泛使用的去模糊数据集，包含了使用GoPro相机拍摄的视频帧序列，提供了清晰和对应的模糊图像对。下载链接：[GoPro Dataset](https://github.com/csjliang/DeblurGAN)
- REDS Dataset：由NTIRE挑战赛发布，包含高质量的视频序列，可用于生成清晰/模糊图像对。下载链接：[REDS Dataset](https://seungjunnah.github.io/Datasets/reds.html)

### 自行合成数据

- 视频帧平均：使用高帧率视频拍摄，然后对连续多帧进行平均或叠加模拟运动模糊，同时保留其中一帧作为清晰图像。
- 模拟运动模糊：对清晰图像应用运动模糊滤波器，使用已知的运动模糊核（如线性、径向等），生成对应的模糊图像。

确保模糊和清晰图像的文件名一一对应。

## 训练模型

```bash
python main.py
```
训练过程中，模型的权重会在每个epoch结束时自动保存为‘model_epoch_{epoch_number}.pth’ 文件。

